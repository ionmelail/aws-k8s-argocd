name: Deploy EKS & ArgoCD

on:
  push:
    branches:
      - argo

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    
      # 1Ô∏è‚É£ Checkout Repository Code
      - name: Checkout Code
        uses: actions/checkout@v3

 
      #  Step 2: Configure AWS Credentials using GitHub Secrets
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2

      #  Step 3: Set up Terraform for Infrastructure Provisioning
      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v2

      # 4Ô∏è‚É£ Make Deployment Script Executable & Run It
      - name: Make Deployment Script Executable
        run: chmod +x scripts/Aws_K8s_Argocd.sh  

      - name: Run Deployment Script
        run: ./scripts/Aws_K8s_Argocd.sh  

      # 5Ô∏è‚É£ Initialize and Apply Terraform Configuration for EKS
      - name: Terraform Init & Apply
        run: |
          cd terraform
          terraform init
          terraform apply -auto-approve

      # 6Ô∏è‚É£ Update Kubeconfig to Access EKS Cluster
      - name: Update kubeconfig
        run: aws eks --region us-west-2 update-kubeconfig --name my-cluster

      # 7Ô∏è‚É£ Create ArgoCD Namespace if Not Exists
      - name: Create ArgoCD namespace
        run: |
          kubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -

      # 8Ô∏è‚É£ Ensure ArgoCD Admin Secret Exists
      - name: Ensure ArgoCD Secret Exists
        run: |
          if ! kubectl get secret argocd-secret -n argocd; then
            kubectl create secret generic argocd-secret -n argocd --from-literal=admin.password='$2a$10$wEJ.NXBfjRj9JQ0QeqA1OuD4/2H6pRxH3p80fD/QFOhH8sD/jq12y'
          fi



      # 9Ô∏è‚É£ Install ArgoCD in the 'argocd' Namespace
      - name: Install ArgoCD
        run: |
          kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

       # 10. Install ArgoCD in the 'argocd' namespace
      - name: Wait for ArgoCD Pods to be Ready
        run: |
          echo "Waiting for all ArgoCD pods to be ready..."
          while [[ $(kubectl get pods -n argocd --no-headers | grep -c -v "Running") -ne 0 ]]; do
            echo "Some pods are still not ready..."
            kubectl get pods -n argocd
            sleep 10
          done
          echo "All ArgoCD pods are running!"

      # 11. Install ArgoCD in the 'argocd' namespace
      - name: Wait for All ArgoCD Pods to be Ready
        run: |
          echo "Waiting for all ArgoCD pods to be ready..."
          for i in {1..30}; do
            READY_PODS=$(kubectl get pods -n argocd --no-headers | awk '{print $2}' | grep -c "1/1")
            TOTAL_PODS=$(kubectl get pods -n argocd --no-headers | wc -l)
      
            if [[ "$READY_PODS" -eq "$TOTAL_PODS" ]]; then
              echo "‚úÖ All ArgoCD pods are ready!"
              exit 0
            fi
      
            echo "‚è≥ Waiting... $READY_PODS/$TOTAL_PODS pods are ready."
            sleep 10
          done
    
          echo "‚ùå Error: ArgoCD pods failed to reach 1/1 READY state."


# # üîπ Install eksctl (Required for AWS Load Balancer Controller)
# - name: Install eksctl
#   run: |
#     echo "Installing eksctl..."
#     curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_Linux_amd64.tar.gz" | tar xz -C /tmp
#     sudo mv /tmp/eksctl /usr/local/bin
#     echo "‚úÖ eksctl installed successfully!"


      # Run echo "Checking AWS Load Balancer Controller in cluster..."
      #   echo "Checking AWS Load Balancer Controller in cluster..."
      #   if ! kubectl get deployment -n kube-system aws-load-balancer-controller > /dev/null 2>&1; then
      #     echo "üöÄ Installing AWS Load Balancer Controller..."
      #     eksctl utils associate-iam-oidc-provider --region us-west-2 --cluster my-cluster --approve
      #     helm repo add eks https://aws.github.io/eks-charts
      #     helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
      #       --set clusterName=my-cluster \
      #       --set serviceAccount.create=true \
      #       --set region=us-west-2 \
      #       --set vpcId=$(aws ec2 describe-vpcs --query "Vpcs[0].VpcId" --output text --region us-west-2) \
      #       -n kube-system
      #   else
      #     echo "‚úÖ AWS Load Balancer Controller is already installed."
      #   fi
      #   shell: /usr/bin/bash -e {0}
      #   env:
      #     AWS_DEFAULT_REGION: us-west-2
      #     AWS_REGION: us-west-2
      #     AWS_ACCESS_KEY_ID: ***
      #     AWS_SECRET_ACCESS_KEY: ***
      #     TERRAFORM_CLI_PATH: /home/runner/work/_temp/03fabad4-08e6-493f-b4e5-c7bc720eb2e9
      # Checking AWS Load Balancer Controller in cluster...
      # üöÄ Installing AWS Load Balancer Controller...
      # /home/runner/work/_temp/add843ae-8aa7-4cea-91e2-41a34fa93650.sh: line 4: eksctl: command not found

      # ‚úÖ Install eksctl (Required for Load Balancer Controller)
      - name: Install eksctl
        run: |
          echo "Installing eksctl..."
          curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin
          eksctl version
          echo "‚úÖ eksctl installed successfully!"


      - name: Install AWS Load Balancer Controller
        run: |
          echo "Checking AWS Load Balancer Controller in cluster..."
          if ! kubectl get deployment -n kube-system aws-load-balancer-controller > /dev/null 2>&1; then
            echo "üöÄ Installing AWS Load Balancer Controller..."
            eksctl utils associate-iam-oidc-provider --region us-west-2 --cluster my-cluster --approve
            helm repo add eks https://aws.github.io/eks-charts
            helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
              --set clusterName=my-cluster \
              --set serviceAccount.create=true \
              --set region=us-west-2 \
              --set vpcId=$(aws ec2 describe-vpcs --query "Vpcs[0].VpcId" --output text --region us-west-2) \
              -n kube-system
          else
            echo "‚úÖ AWS Load Balancer Controller is already installed."
          fi



      # # üîπ Install AWS Load Balancer Controller
      # - name: Install AWS Load Balancer Controller
      #   run: |
      #     echo "Checking AWS Load Balancer Controller in cluster..."
      #     if ! kubectl get deployment -n kube-system aws-load-balancer-controller > /dev/null 2>&1; then
      #       echo "üöÄ Installing AWS Load Balancer Controller..."
      #       eksctl utils associate-iam-oidc-provider --region us-west-2 --cluster my-cluster --approve
      #       helm repo add eks https://aws.github.io/eks-charts
      #       helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
      #         --set clusterName=my-cluster \
      #         --set serviceAccount.create=true \
      #         --set region=us-west-2 \
      #         --set vpcId=$(aws ec2 describe-vpcs --query "Vpcs[0].VpcId" --output text --region us-west-2) \
      #         -n kube-system
      #     else
      #       echo "‚úÖ AWS Load Balancer Controller is already installed."
      #     fi
      
      
      # üîπ Ensure AWS Load Balancer Controller IAM Policy Has Correct Permissions
      - name: Attach Permissions to AWS Load Balancer IAM Policy
        run: |
          echo "üîç Checking and attaching permissions to AmazonEKSLoadBalancerController policy..."
          
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          POLICY_ARN="arn:aws:iam::$AWS_ACCOUNT_ID:policy/AmazonEKSLoadBalancerController"
      
          # Download the official AWS IAM policy JSON
          curl -s -o iam_policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/main/docs/install/iam_policy.json
      
          # Ensure the file was downloaded successfully
          if [ ! -f "iam_policy.json" ]; then
            echo "‚ùå ERROR: Failed to download iam_policy.json"
            exit 1
          fi
      
          # Check if the policy has existing versions
          POLICY_VERSIONS=$(aws iam list-policy-versions --policy-arn "$POLICY_ARN" --query "Versions[].VersionId" --output text)
          
          # Delete older versions if there are more than 5 (IAM policies have a limit)
          while [ "$(echo "$POLICY_VERSIONS" | wc -w)" -ge 5 ]; do
            OLDEST_VERSION=$(echo "$POLICY_VERSIONS" | awk '{print $1}')
            echo "üóë Removing old policy version: $OLDEST_VERSION"
            aws iam delete-policy-version --policy-arn "$POLICY_ARN" --version-id "$OLDEST_VERSION"
            POLICY_VERSIONS=$(aws iam list-policy-versions --policy-arn "$POLICY_ARN" --query "Versions[].VersionId" --output text)
          done
      
          # Create a new version of the policy with correct permissions
          echo "üîÑ Updating IAM Policy with correct permissions..."
          aws iam create-policy-version --policy-arn "$POLICY_ARN" --policy-document file://iam_policy.json --set-as-default
      
          echo "‚úÖ Permissions successfully attached to AmazonEKSLoadBalancerController IAM Policy!"



      # üîπ Ensure IAM Policy is Fully Available Before Attaching
      - name: Ensure IAM Policy Exists Before Attaching
        run: |
          POLICY_ARN="arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:policy/AmazonEKSLoadBalancerController"
          MAX_RETRIES=15  # Allow up to ~8 minutes for IAM policy propagation
          WAIT_TIME=30  # Start with 30 seconds
      
          echo "‚úÖ Ensuring IAM policy exists before attaching..."
      
          # Explicitly wait for AWS to confirm policy exists
          aws iam wait policy-exists --policy-arn "$POLICY_ARN" || echo "‚è≥ Initial wait failed. Retrying manually."
      
          # Retry with exponential backoff
          for i in $(seq 1 $MAX_RETRIES); do
            if aws iam get-policy --policy-arn "$POLICY_ARN" > /dev/null 2>&1; then
              echo "‚úÖ IAM Policy is now available!"
              exit 0
            fi
            echo "‚è≥ IAM Policy not available yet. Retrying in $WAIT_TIME seconds..."
            sleep $WAIT_TIME
            WAIT_TIME=$((WAIT_TIME * 2))  # Exponential backoff (30s, 60s, 120s, etc.)
          done
      
          echo "‚ùå ERROR: IAM Policy did not become available in time!"
          exit 1


      
      # # ‚úÖ Step X: Ensure IAM Policy is Fully Available Before Attaching
      # - name: Ensure IAM Policy Exists Before Attaching
      #   run: |
      #     POLICY_ARN="arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:policy/AmazonEKSLoadBalancerController"
      #     MAX_RETRIES=15  # Allow up to ~8 minutes for IAM policy propagation
      #     WAIT_TIME=30  # Start with 30 seconds

      #     echo "‚úÖ Ensuring IAM policy exists before attaching..."
          
      #     for i in $(seq 1 $MAX_RETRIES); do
      #       if aws iam get-policy --policy-arn "$POLICY_ARN" > /dev/null 2>&1; then
      #         echo "‚úÖ IAM Policy is now available!"
      #         exit 0
      #       fi
      #       echo "‚è≥ IAM Policy not available yet. Retrying in $WAIT_TIME seconds..."
      #       sleep $WAIT_TIME
      #       WAIT_TIME=$((WAIT_TIME * 2))  # Exponential backoff (30s, 60s, 120s, etc.)
      #     done

      #     echo "‚ùå ERROR: IAM Policy did not become available in time!"
      #     exit 1







      - name: Validate AWS Load Balancer IAM Policy
        run: |
          echo "Checking AWS IAM Policy for LoadBalancer Controller..."
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          POLICY_ARN="arn:aws:iam::$AWS_ACCOUNT_ID:policy/AmazonEKSLoadBalancerController"
      
          if aws iam get-policy --policy-arn "$POLICY_ARN" > /dev/null 2>&1; then
            echo "‚úÖ IAM Policy exists: $POLICY_ARN"
          else
            echo "‚ö†Ô∏è WARNING: IAM Policy not found! Creating policy..."
            aws iam create-policy --policy-name AmazonEKSLoadBalancerController \
              --policy-document file://iam_policy.json
          fi

          # - name: Install AWS Load Balancer Controller
          #   run: |
          #     echo "Checking AWS Load Balancer Controller in cluster..."
          #     if ! kubectl get deployment -n kube-system aws-load-balancer-controller > /dev/null 2>&1; then
          #       echo "üöÄ Installing AWS Load Balancer Controller..."
          #       eksctl utils associate-iam-oidc-provider --region us-west-2 --cluster my-cluster --approve
          #       helm repo add eks https://aws.github.io/eks-charts
          #       helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
          #         --set clusterName=my-cluster \
          #         --set serviceAccount.create=true \
          #         --set region=us-west-2 \
          #         --set vpcId=$(aws ec2 describe-vpcs --query "Vpcs[0].VpcId" --output text --region us-west-2) \
          #         -n kube-system
          #     else
          #       echo "‚úÖ AWS Load Balancer Controller is already installed."
          #     fi
  

          
      
      # ‚úÖ Step X+2: Deploy AWS Load Balancer Controller
      - name: Deploy AWS Load Balancer Controller
        run: |
          kubectl apply -k github.com/aws/eks-charts/stable/aws-load-balancer-controller//crds?ref=master
          helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
            --set clusterName=my-cluster \
            --set serviceAccount.create=false \
            --set serviceAccount.name=aws-load-balancer-controller \
            -n kube-system
          echo "‚úÖ AWS Load Balancer Controller installed!"



      # ‚úÖ Step 11: Apply LoadBalancer for ArgoCD Server
      - name: Apply LoadBalancer to ArgoCD Server
        run: |
          echo "Applying LoadBalancer to ArgoCD server..."
          kubectl apply -f argocd/argocd-server-loadbalancer.yaml
          echo "‚úÖ LoadBalancer configuration applied!"

      # ‚úÖ Step 12: Ensure argocd-redis Secret Exists BEFORE ArgoCD Restarts
      - name: Ensure ArgoCD Redis Secret Exists
        run: |
          if ! kubectl get secret argocd-redis -n argocd; then
            kubectl create secret generic argocd-redis -n argocd --from-literal=password=$(openssl rand -base64 32)
          fi



      # 1Ô∏è‚É£1Ô∏è‚É£ Check ArgoCD Services and Pods
      - name: Check ArgoCD pods and services
        run: |
          kubectl get pods -n argocd
          kubectl get svc -n argocd

      # 1Ô∏è‚É£2Ô∏è‚É£ Ensure 'demo-app' Namespace Exists
      - name: Ensure demo-app Namespace Exists
        run: |
          if ! kubectl get namespace demo-app; then
            echo "Creating demo-app namespace..."
            kubectl create namespace demo-app
          else
            echo "Namespace demo-app already exists."
          fi

   
      # 1Ô∏è‚É£5Ô∏è‚É£ Check Deployed ArgoCD Applications
      - name: Check ArgoCD Applications
        run: |
          kubectl get applications -n argocd

      # 1Ô∏è‚É£6Ô∏è‚É£ Restart ArgoCD Pods if Needed
      - name: Restart ArgoCD Pods if Needed
        run: |
          if [[ $(kubectl get pods -n argocd | grep -c "Running") -lt 5 ]]; then
            kubectl delete pod -n argocd --all
          fi

           # 5.1. Install ArgoCD in the 'argocd' namespace
      - name: Wait for ArgoCD Pods to be Ready
        run: |
          echo "Waiting for all ArgoCD pods to be ready..."
          while [[ $(kubectl get pods -n argocd --no-headers | grep -c -v "Running") -ne 0 ]]; do
            echo "Some pods are still not ready..."
            kubectl get pods -n argocd
            sleep 10
          done
          echo "All ArgoCD pods are running!"

      # 5.2. Install ArgoCD in the 'argocd' namespace
      - name: Wait for All ArgoCD Pods to be Ready
        run: |
          echo "Waiting for all ArgoCD pods to be ready..."
          for i in {1..30}; do
            READY_PODS=$(kubectl get pods -n argocd --no-headers | awk '{print $2}' | grep -c "1/1")
            TOTAL_PODS=$(kubectl get pods -n argocd --no-headers | wc -l)
      
            if [[ "$READY_PODS" -eq "$TOTAL_PODS" ]]; then
              echo "‚úÖ All ArgoCD pods are ready!"
              exit 0
            fi
      
            echo "‚è≥ Waiting... $READY_PODS/$TOTAL_PODS pods are ready."
            sleep 10
          done
    
          echo "‚ùå Error: ArgoCD pods failed to reach 1/1 READY state."

                # ‚úÖ Step 15.1: Validate AWS Load Balancer Controller IAM Policy (Graceful Failure)
      - name: Validate AWS Load Balancer IAM Policy
        run: |
          echo "Checking AWS IAM Policy for LoadBalancer Controller..."
          POLICY_ARN="arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:policy/AmazonEKSLoadBalancerController"
          if aws iam get-policy --policy-arn "$POLICY_ARN"; then
            echo "‚úÖ IAM Policy exists."
          else
            echo "‚ö†Ô∏è WARNING: IAM Policy not found. Ensure the LoadBalancer Controller has the correct permissions."
          fi

      # ‚úÖ Step 16: Wait for ArgoCD Server LoadBalancer IP (Retries)
      - name: Wait for ArgoCD Server LoadBalancer
        run: |
          echo "Waiting for ArgoCD server LoadBalancer IP..."
          for i in {1..30}; do
            ARGOCD_SERVER=$(kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
            if [[ -n "$ARGOCD_SERVER" ]]; then
              echo "‚úÖ ArgoCD Server Ready: $ARGOCD_SERVER"
              echo "ARGOCD_SERVER=$ARGOCD_SERVER" >> $GITHUB_ENV
              exit 0
            fi
            echo "‚è≥ ArgoCD server address not available yet. Retrying in 10s..."
            sleep 10
          done
          echo "‚ùå ERROR: ArgoCD server LoadBalancer IP not found. Check Kubernetes events."
          kubectl get events -n argocd --sort-by=.metadata.creationTimestamp
          exit 1


      # # 2Ô∏è‚É£2Ô∏è‚É£ Verify load and all 
      # - name: Verify load and all 
      #   run: |
      #     kubectl get svc argocd-server -n argocd
      #     kubectl get pods -n kube-system | grep aws-load-balancer
      #     aws iam get-policy --policy-arn arn:aws:iam::<AWS_ACCOUNT_ID>:policy/AmazonEKSLoadBalancerController

          
      # ‚úÖ Step 14: Get ArgoCD Server Address (with Wait Loop)
      - name: Get ArgoCD Server Address
        run: |
          echo "Waiting for ArgoCD server address..."
          for i in {1..30}; do
            ARGOCD_SERVER=$(kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
            if [[ -n "$ARGOCD_SERVER" ]]; then
              echo "‚úÖ ArgoCD Server Address: $ARGOCD_SERVER"
              echo "ARGOCD_SERVER=$ARGOCD_SERVER" >> $GITHUB_ENV
              exit 0
            fi
            echo "‚è≥ ArgoCD server address not available yet. Retrying in 10s..."
            sleep 10
          done
          echo "‚ùå ERROR: ArgoCD server address not found after waiting."
          exit 1


      # 1Ô∏è‚É£8Ô∏è‚É£ Retrieve ArgoCD Admin Password
      - name: Get ArgoCD Admin Password
        run: |
          echo "Retrieving ArgoCD admin password..."
          ARGOCD_ADMIN_PASSWORD=$(kubectl get secret argocd-initial-admin-secret -n argocd -o jsonpath="{.data.password}" | base64 --decode)
          if [[ -z "$ARGOCD_ADMIN_PASSWORD" ]]; then
            echo "‚ùå ERROR: Unable to retrieve ArgoCD admin password."
            exit 1
          fi
          echo "::add-mask::$ARGOCD_ADMIN_PASSWORD"
          echo "ARGOCD_ADMIN_PASSWORD=$ARGOCD_ADMIN_PASSWORD" >> $GITHUB_ENV

      # 1Ô∏è‚É£9Ô∏è‚É£ Log in to ArgoCD
      - name: Login to ArgoCD
        run: |
          echo "Logging into ArgoCD..."
          argocd login "$ARGOCD_SERVER" --username admin --password "$ARGOCD_ADMIN_PASSWORD" --insecure
          echo "‚úÖ Successfully logged into ArgoCD."

   # 1Ô∏è‚É£3Ô∏è‚É£ Perform Dry-Run Deployment of ArgoCD Application
      - name: Check Dry-Run Applications
        run: |
          kubectl apply -f argocd/application.yaml --dry-run=client

      # 1Ô∏è‚É£4Ô∏è‚É£ Deploy Application with ArgoCD
      - name: Deploy Application with ArgoCD
        run: |
          kubectl apply -f argocd/application.yaml


      # 2Ô∏è‚É£0Ô∏è‚É£ Sync Application with ArgoCD
      - name: Sync ArgoCD Application
        run: |
          echo "Syncing demo-app with ArgoCD..."
          argocd app sync demo-app
          echo "‚úÖ ArgoCD application sync initiated."

      # 2Ô∏è‚É£1Ô∏è‚É£ Check All Namespaces
      - name: Check namespaces
        run: |
          kubectl get namespaces

      # 2Ô∏è‚É£2Ô∏è‚É£ Verify Deployment of Demo-App
      - name: Verify Deployment
        run: |
          kubectl get pods -n demo-app
          kubectl get svc -n demo-app

      # 2Ô∏è‚É£3Ô∏è‚É£ Debugging Step: Collect Logs if ArgoCD Fails
      - name: Debugging - Get Failing Pod Logs
        if: failure()
        run: |
          echo "Fetching logs from ArgoCD pods..."
          kubectl get pods -n argocd
          kubectl logs -n argocd -l app.kubernetes.io/name=argocd-server || true
          kubectl logs -n argocd -l app.kubernetes.io/name=argocd-application-controller || true

      # 2Ô∏è‚É£4Ô∏è‚É£ Debugging Step: Describe Failing ArgoCD Pods
      - name: Debugging - Describe Failing Pods
        if: failure()
        run: |
          echo "Describing problematic pods..."
          kubectl describe pod -n argocd -l app.kubernetes.io/name=argocd-server || true
          kubectl describe pod -n argocd -l app.kubernetes.io/name=argocd-application-controller || true

      # 2Ô∏è‚É£5Ô∏è‚É£ Debugging Step: Get Recent Kubernetes Events
      - name: Debugging - Get Kubernetes Events
        if: failure()
        run: |
          echo "Checking Kubernetes events..."
          kubectl get events -n argocd --sort-by=.metadata.creationTimestamp || true
